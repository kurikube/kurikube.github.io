[{"content":"背景 CentOS7を新規インストール時、不要なパッケージを入れたくなかったので「Minimal ISO」のイメージを使用しました。当然ながらGUI環境が入ってなかったので、GUIを使えるように、追加でインストールを行いました。\nGUI環境のインストール まずはGUI環境を以下のコマンドでインストールします。「groupinstall」を使えば、関連するパッケージ群を1つのグループとしてまとめてインストール可能です。\nsudo yum -y groupinstall \u0026#34;GNOME Desktop\u0026#34; GUIを有効化する GUI環境一式のインストール完了したら、以下のコマンドでGUIを有効にします。\nstartx 有効化すると以下のような初期設定画面が表示されるので、言語設定などをします。 初期設定が完了すると、GUI環境で作業ができるようになる。 GUI環境で起動するようにする GUI環境は整ったが、このままではシステムを再起動するとCUIに戻ってしまいます。\n次回起動時もGUI環境で立ち上げたい場合は、システム起動時のランレベルを変えてあげる必要があります。ランレベルは簡単に言えば「起動モード」みたいなものです。\nsudo systemctl set-default graphical.target これで次回起動時からGUI環境で立ち上がるようになります。ちなみに、「やっぱり起動時はCUIにしたい」というときは以下のコマンドで元に戻せます。\nsudo systemctl set-default multi-user.target ","permalink":"https://kurikube.github.io/post/20220128/","summary":"背景 CentOS7を新規インストール時、不要なパッケージを入れたくなかったので「Minimal ISO」のイメージを使用しました。当然ながらGUI環境が入ってなかったので、GUIを使えるように、追加でインストールを行いました。\nGUI環境のインストール まずはGUI環境を以下のコマンドでインストールします。「groupinstall」を使えば、関連するパッケージ群を1つのグループとしてまとめてインストール可能です。\nsudo yum -y groupinstall \u0026#34;GNOME Desktop\u0026#34; GUIを有効化する GUI環境一式のインストール完了したら、以下のコマンドでGUIを有効にします。\nstartx 有効化すると以下のような初期設定画面が表示されるので、言語設定などをします。 初期設定が完了すると、GUI環境で作業ができるようになる。 GUI環境で起動するようにする GUI環境は整ったが、このままではシステムを再起動するとCUIに戻ってしまいます。\n次回起動時もGUI環境で立ち上げたい場合は、システム起動時のランレベルを変えてあげる必要があります。ランレベルは簡単に言えば「起動モード」みたいなものです。\nsudo systemctl set-default graphical.target これで次回起動時からGUI環境で立ち上がるようになります。ちなみに、「やっぱり起動時はCUIにしたい」というときは以下のコマンドで元に戻せます。\nsudo systemctl set-default multi-user.target ","title":"最小インストールしたCentOS7にGUIを導入する"},{"content":"CRC VMの内部動作を確認する CRC VMのIPアドレスを確認する\n[centos@ip-172-31-19-74 ~]$ crc ip 192.168.130.11 CRC VMへSSH接続する\n[centos@ip-172-31-19-74 ~]$ ssh -i ~/.crc/machines/crc/id_ecdsa core@$CRC_IP CRC VMの中でpodmanでdnsmasq(DNSサーバ)が起動していることが分かる\n[core@crc-xxcfw-master-0 ~]$ sudo podman ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 128a6fe17e5e quay.io/crcont/gvisor-tap-vsock:3231aba53905468c22e394493a0debc1a6cc6392 3 weeks ago Exited (0) 7 hours ago gvisor-tap-vsock e3593ab79e1d quay.io/crcont/dnsmasq:latest 3 weeks ago Up 7 hours ago 0.0.0.0:53-\u0026gt;53/udp crc-dnsmasq CRC実行ホストのNetwork Manager設定 CRCセットアップ後のホスト上のdnsmasqのCRC用インスタンスは下記のようになっています。\n[centos@ip-172-31-19-74 ~]$ cat /etc/NetworkManager/dnsmasq.d/crc.conf server=/apps-crc.testing/192.168.130.11 server=/crc.testing/192.168.130.11 なお、このcrc.confはcrc setupおよびcrc start時にチェックされ、設定を変更することができません\nCRCホストの/etc/hosts CRCセットアップ後、CRCを実行するホストの/etc/hostsには設定が追加されます\n[centos@ip-172-31-19-74 ~]$ sudo cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.130.11 api.crc.testing canary-openshift-ingress-canary.apps-crc.testing console-openshift-console.apps-crc.testing default-route-openshift-image-registry.apps-crc.testing downloads-openshift-console.apps-crc.testing oauth-openshift.apps-crc.testing リモート接続を構成する [centos@ip-172-31-19-74 ~]$ sudo yum install haproxy policycoreutils-python-utils jq [centos@ip-172-31-19-74 ~]$ yum update [centos@ip-172-31-19-74 ~]$ sudo yum install epel-release [centos@ip-172-31-19-74 ~]$ sudo yum install haproxy policycoreutils-python-utils jq [centos@ip-172-31-19-74 ~]$ yum search policycoreutils-python [centos@ip-172-31-19-74 ~]$ sudo yum install policycoreutils-python SELinuxのためのTCPポート6443のリッスンを許可します。\n[centos@ip-172-31-19-74 ~]$ sudo semanage port -a -t http_port_t -p tcp 6443 sudo cp /etc/haproxy/haproxy.cfg{,.bak} [centos@ip-172-31-19-74 ~]$ sudo cp /etc/haproxy/haproxy.cfg{,.bak}\nhaproxyのコンフィグを作成します。コンフィグ内の$CRC_IPにはCRCのIPアドレスが記載されます。\n[centos@ip-172-31-19-74 ~]$ export CRC_IP=$(crc ip) [centos@ip-172-31-19-74 ~]$ sudo tee /etc/haproxy/haproxy.cfg \u0026amp;\u0026gt;/dev/null \u0026lt;\u0026lt;EOF \u0026gt; global \u0026gt; debug \u0026gt; \u0026gt; defaults \u0026gt; log global \u0026gt; mode http \u0026gt; timeout connect 5000 \u0026gt; timeout client 500000 \u0026gt; timeout server 500000 \u0026gt; \u0026gt; frontend apps \u0026gt; bind 0.0.0.0:80 \u0026gt; option tcplog \u0026gt; mode tcp \u0026gt; default_backend apps \u0026gt; \u0026gt; frontend apps_ssl \u0026gt; bind 0.0.0.0:443 \u0026gt; option tcplog \u0026gt; mode tcp \u0026gt; default_backend apps_ssl \u0026gt; \u0026gt; backend apps \u0026gt; mode tcp \u0026gt; balance roundrobin \u0026gt; server webserver1 $CRC_IP:80 check \u0026gt; \u0026gt; backend apps_ssl \u0026gt; mode tcp \u0026gt; balance roundrobin \u0026gt; option ssl-hello-chk \u0026gt; server webserver1 $CRC_IP:443 check \u0026gt; \u0026gt; frontend api \u0026gt; bind 0.0.0.0:6443 \u0026gt; option tcplog \u0026gt; mode tcp \u0026gt; default_backend api \u0026gt; \u0026gt; backend api \u0026gt; mode tcp \u0026gt; balance roundrobin \u0026gt; option ssl-hello-chk \u0026gt; server webserver1 $CRC_IP:6443 check \u0026gt; EOF haproxyのサービス登録とサービスの起動を行います\n[centos@ip-172-31-19-74 ~]$ sudo systemctl enable haproxy Created symlink from /etc/systemd/system/multi-user.target.wants/haproxy.service to /usr/lib/systemd/system/haproxy.service. [centos@ip-172-31-19-74 ~]$ sudo systemctl start haproxy [centos@ip-172-31-19-74 ~]$ sudo yum install dnsmasq -y [centos@ip-172-31-19-74 ~]$ sudo mv /etc/dnsmasq.conf{,.bak} [centos@ip-172-31-19-74 ~]$ sudo tee /etc/dnsmasq.conf \u0026amp;\u0026gt;/dev/null \u0026lt;\u0026lt;EOF \u0026gt; user=dnsmasq \u0026gt; group=dnsmasq \u0026gt; no-hosts \u0026gt; bind-interfaces \u0026gt; listen-address=192.168.1.25 \u0026gt; address=/testing/192.168.1.25 \u0026gt; EOF クライアント側の/etc/hostsにCRCサーバのレコードを追加する cat /etc/hosts \u0026lt;CRCサーバのIPアドレス\u0026gt; console-openshift-console.apps-crc.testing oauth-openshift.apps-crc.testing 接続してみる とりあえず証明書のエラーは無視しました。 アクセスできました。\n参考にさせて頂いた記事  https://rheb.hatenablog.com/entry/crc_remote_connecting https://crc.dev/crc/#setting-up-remote-server_gsg https://rheb.hatenablog.com/entry/2021/03/30/crc_tips https://tex2e.github.io/blog/linux/install-semanage  ","permalink":"https://kurikube.github.io/post/20220124/","summary":"CRC VMの内部動作を確認する CRC VMのIPアドレスを確認する\n[centos@ip-172-31-19-74 ~]$ crc ip 192.168.130.11 CRC VMへSSH接続する\n[centos@ip-172-31-19-74 ~]$ ssh -i ~/.crc/machines/crc/id_ecdsa core@$CRC_IP CRC VMの中でpodmanでdnsmasq(DNSサーバ)が起動していることが分かる\n[core@crc-xxcfw-master-0 ~]$ sudo podman ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 128a6fe17e5e quay.io/crcont/gvisor-tap-vsock:3231aba53905468c22e394493a0debc1a6cc6392 3 weeks ago Exited (0) 7 hours ago gvisor-tap-vsock e3593ab79e1d quay.io/crcont/dnsmasq:latest 3 weeks ago Up 7 hours ago 0.0.0.0:53-\u0026gt;53/udp crc-dnsmasq CRC実行ホストのNetwork Manager設定 CRCセットアップ後のホスト上のdnsmasqのCRC用インスタンスは下記のようになっています。\n[centos@ip-172-31-19-74 ~]$ cat /etc/NetworkManager/dnsmasq.d/crc.conf server=/apps-crc.testing/192.168.130.11 server=/crc.testing/192.168.130.11 なお、このcrc.confはcrc setupおよびcrc start時にチェックされ、設定を変更することができません\nCRCホストの/etc/hosts CRCセットアップ後、CRCを実行するホストの/etc/hostsには設定が追加されます\n[centos@ip-172-31-19-74 ~]$ sudo cat /etc/hosts 127.","title":"CodeReady Containers（CRC）をリモート接続可能にする"},{"content":"背景 Linuxでコマンドの実行ログを保存したいことは非常に多いと思います。これは、後で見返せるようにするためでもありますし、派遣社員などの場合は自分の身を守るための手段にもなります。\n使用方法 script \u0026lt;ログを保存したいファイル名\u0026gt; ファイル名を指定しなかった場合は、カレントディレクトリにtypescript というファイルで保存されます\n$ script スクリプトを開始しました、ファイルは typescript です $ date 2021年 3月 28日 日曜日 06:46:13 EDT 終了する場合はexitするかctrl+dを実行します\n$ exit exit スクリプトを終了しました、ファイルは typescript です ファイルにログが残っているか確認する\n$ cat typescript スクリプトは 2021年03月28日 06時46分11秒 に開始しました$ date 2021年 3月 28日 日曜日 06:46:13 EDT $ exit exit スクリプトは 2021年03月28日 06時47分10秒 に終了しました きちんと記録されていました。 最後になりますが、ファイルへの追記方法を記載します。 同じファイルに追記したい場合はオプション-aを使うことで可能です。\n","permalink":"https://kurikube.github.io/post/20210130/","summary":"背景 Linuxでコマンドの実行ログを保存したいことは非常に多いと思います。これは、後で見返せるようにするためでもありますし、派遣社員などの場合は自分の身を守るための手段にもなります。\n使用方法 script \u0026lt;ログを保存したいファイル名\u0026gt; ファイル名を指定しなかった場合は、カレントディレクトリにtypescript というファイルで保存されます\n$ script スクリプトを開始しました、ファイルは typescript です $ date 2021年 3月 28日 日曜日 06:46:13 EDT 終了する場合はexitするかctrl+dを実行します\n$ exit exit スクリプトを終了しました、ファイルは typescript です ファイルにログが残っているか確認する\n$ cat typescript スクリプトは 2021年03月28日 06時46分11秒 に開始しました$ date 2021年 3月 28日 日曜日 06:46:13 EDT $ exit exit スクリプトは 2021年03月28日 06時47分10秒 に終了しました きちんと記録されていました。 最後になりますが、ファイルへの追記方法を記載します。 同じファイルに追記したい場合はオプション-aを使うことで可能です。","title":"scriptコマンドでコマンド実行の作業ログを保存する"},{"content":"背景 CentOS 7 にはデフォルトでFirefoxがインストールされてます。しかし、Google Chromeの方がより便利なこともあるので、Chromeをインストールする方法を紹介します\n環境確認 [cloudg@localhost ~]$ cat /etc/redhat-release CentOS Linux release 7.9.2009 (Core) レポジトリファイルの作成 [cloudg@localhost ~]$ vi /etc/yum.repos.d/google.chrome.repo 下記の内容を記載する。\n[google-chrome] name=google-chrome baseurl=http://dl.google.com/linux/chrome/rpm/stable/$basearch enabled=1 gpgcheck=1 gpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub インストール [cloudg@localhost ~]$ yum install google-chrome-stable Internet の部分にGoogle Chromeが表示される 起動方法 下記コマンドで起動できる\n[cloudg@localhost ~]# google-chrome エラーが発生する場合 下記のエラーが発生することがある。\n[root@localhost ~]# google-chrome [4206:4206:0327/064251.530967:ERROR:zygote_host_impl_linux.cc(90)] Running as root without --no-sandbox is not supported. See https://crbug.com/63818 /opt/google/chrome/google-chromeの一番最後の行を変更する\nvi /opt/google/chrome/google-chrome exec -a \u0026quot;$0\u0026quot; \u0026quot;$HERE/chrome\u0026quot; \u0026quot;$@\u0026quot; --no-sandbox --user-data-dir=~ これで問題なく起動できるようになります。\n","permalink":"https://kurikube.github.io/post/20220131/","summary":"背景 CentOS 7 にはデフォルトでFirefoxがインストールされてます。しかし、Google Chromeの方がより便利なこともあるので、Chromeをインストールする方法を紹介します\n環境確認 [cloudg@localhost ~]$ cat /etc/redhat-release CentOS Linux release 7.9.2009 (Core) レポジトリファイルの作成 [cloudg@localhost ~]$ vi /etc/yum.repos.d/google.chrome.repo 下記の内容を記載する。\n[google-chrome] name=google-chrome baseurl=http://dl.google.com/linux/chrome/rpm/stable/$basearch enabled=1 gpgcheck=1 gpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub インストール [cloudg@localhost ~]$ yum install google-chrome-stable Internet の部分にGoogle Chromeが表示される 起動方法 下記コマンドで起動できる\n[cloudg@localhost ~]# google-chrome エラーが発生する場合 下記のエラーが発生することがある。\n[root@localhost ~]# google-chrome [4206:4206:0327/064251.530967:ERROR:zygote_host_impl_linux.cc(90)] Running as root without --no-sandbox is not supported. See https://crbug.com/63818 /opt/google/chrome/google-chromeの一番最後の行を変更する\nvi /opt/google/chrome/google-chrome exec -a \u0026quot;$0\u0026quot; \u0026quot;$HERE/chrome\u0026quot; \u0026quot;$@\u0026quot; --no-sandbox --user-data-dir=~ これで問題なく起動できるようになります。","title":"CentOS 7 にGoogle Chromeをインストールする"},{"content":"概要 OpenShift4.x以降はMinishiftがなくなり、OpenShift CodeReady Container（CRC）となっている。 以下では公式ドキュメントに沿って手元のベアメタルサーバへインストールを行う。このサーバで色々なことを試してみる。 https://crc.dev/crc/\n環境  ホストOS：CentOS7.7 構成図 マシン上でCRCをインストールすると自動的にNWが作成されてCRCが作成される 。 OpenShiftのWebコンソールへアクセスする際には、ベアメタルマシンへリモデスした上でマシン上のブラウザからアクセスする必要がある。 環境確認  [root@ip-172-31-19-74 ~]# cat /etc/redhat-release CentOS Linux release 7.7.1908 (Core) 手順 公式ドキュメントの手順に沿ってインストールする。\n1.NetworkManagerをインストールし、起動する [root@ip-172-31-19-74 ~]# yum -y install NetworkManager [root@ip-172-31-19-74 ~]# systemctl restart NetworkManager 2.資材をダウンロードして、解凍して、パスの通ったフォルダへ移動 [root@ip-172-31-19-74 ~]# yum -y install wget [root@ip-172-31-19-74 tmp]# curl -k -L https://developers.redhat.com/content-gateway/rest/mirror/pub/openshift-v4/clients/crc/latest/crc-linux-amd64.tar.xz -o /tmp/crc-linux-amd64.tar.xz #ダウンロードにかなり時間を要します。 [root@ip-172-31-19-74 ~]# cd /tmp [root@ip-172-31-19-74 tmp]# xz -dc /tmp/crc-linux-amd64.tar.xz | tar xfv - [root@ip-172-31-19-74 tmp]# cp -pi crc-linux-1.38.0-amd64/crc /usr/local/bin 3.初期セットアップ＆起動 crc startすると途中でsecretを聞かれるので、Red Hat Developer アカウントを作成して取得したsecretを入力する。完了するまで数分かかる。非rootユーザで実行する必要がある。 https://cloud.redhat.com/openshift/install/metal/user-provisioned\n[root@ip-172-31-19-74 tmp]# su - centos [centos@ip-172-31-19-74 ~]$ cd [centos@ip-172-31-19-74 ~]$ crc setup Would you like to contribute anonymous usage statistics? [y/N]: N # crcのqcow2をダウンロードするのに時間がかかります。 [centos@ip-172-31-19-74 ~]$ crc start 下記のような出力が表示される\nINFO A CodeReady Containers VM for OpenShift 4.9.12 is already running Started the OpenShift cluster. The server is accessible via web console at: https://console-openshift-console.apps-crc.testing Log in as administrator: Username: kubeadmin Password: wtXdm-cJwtQ-Jo3Ny-hKoRU Log in as user: Username: developer Password: developer Use the \u0026#39;oc\u0026#39; command line interface: $ eval $(crc oc-env) $ oc login -u developer https://api.crc.testing:6443 4.ocコマンドにパスを通す [centos@ip-172-31-19-74 ~]$ crc oc-env [centos@ip-172-31-19-74 ~]$ eval $(crc oc-env) 5.ログイン oc startしたときの出力結果に従ってoc loginする\n[centos@ip-172-31-19-74 ~]$ oc login -u developer https://api.crc.testing:6443 [centos@ip-172-31-19-74 ~]$ oc login -u kubeadmin https://api.crc.testing:6443 6.動作確認 [centos@ip-172-31-19-74 ~]$ oc get node NAME STATUS ROLES AGE VERSION crc-xxcfw-master-0 Ready master,worker 23d v1.22.3+e790d7f 7.試験用プロジェクトの作成と、busybox podの作成 Tempプロジェクトを作成してbusybox podを作成してみる。\n[centos@ip-172-31-19-74 ~]$ oc new-project temp Now using project \u0026#34;temp\u0026#34; on server \u0026#34;https://api.crc.testing:6443\u0026#34;. You can add applications to this project with the \u0026#39;new-app\u0026#39; command. For example, try: oc new-app rails-postgresql-example to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application: kubectl create deployment hello-node --image=k8s.gcr.io/serve_hostname [centos@ip-172-31-19-74 ~]$ oc run busybox --restart=Never --image=busybox pod/busybox created [centos@ip-172-31-19-74 ~]$ oc get po NAME READY STATUS RESTARTS AGE busybox 0/1 Completed 0 23s 最後に CentOSに無事CRCをインストールすることができました。これでOpenShiftについてじっくり学べますね。 最近では書籍も執筆されているようです。良かったら読んでみて下さい。\nOpenShift徹底入門  OpenShift徹底活用ガイド  ","permalink":"https://kurikube.github.io/post/20210131/","summary":"概要 OpenShift4.x以降はMinishiftがなくなり、OpenShift CodeReady Container（CRC）となっている。 以下では公式ドキュメントに沿って手元のベアメタルサーバへインストールを行う。このサーバで色々なことを試してみる。 https://crc.dev/crc/\n環境  ホストOS：CentOS7.7 構成図 マシン上でCRCをインストールすると自動的にNWが作成されてCRCが作成される 。 OpenShiftのWebコンソールへアクセスする際には、ベアメタルマシンへリモデスした上でマシン上のブラウザからアクセスする必要がある。 環境確認  [root@ip-172-31-19-74 ~]# cat /etc/redhat-release CentOS Linux release 7.7.1908 (Core) 手順 公式ドキュメントの手順に沿ってインストールする。\n1.NetworkManagerをインストールし、起動する [root@ip-172-31-19-74 ~]# yum -y install NetworkManager [root@ip-172-31-19-74 ~]# systemctl restart NetworkManager 2.資材をダウンロードして、解凍して、パスの通ったフォルダへ移動 [root@ip-172-31-19-74 ~]# yum -y install wget [root@ip-172-31-19-74 tmp]# curl -k -L https://developers.redhat.com/content-gateway/rest/mirror/pub/openshift-v4/clients/crc/latest/crc-linux-amd64.tar.xz -o /tmp/crc-linux-amd64.tar.xz #ダウンロードにかなり時間を要します。 [root@ip-172-31-19-74 ~]# cd /tmp [root@ip-172-31-19-74 tmp]# xz -dc /tmp/crc-linux-amd64.tar.xz | tar xfv - [root@ip-172-31-19-74 tmp]# cp -pi crc-linux-1.","title":"OpenShift Code ReadyをCentosにインストールする（2022/1/29時点）"},{"content":"概要 OpenShift4.x以降はMinishiftがなくなり、OpenShift CodeReady Container（CRC）となっている。 以下では公式ドキュメントに沿って手元のベアメタルサーバへインストールを行う。このサーバで色々なことを試してみる。 https://code-ready.github.io/crc/\n環境  ホストOS：CentOS7.7 構成図 マシン上でCRCをインストールすると自動的にNWが作成されてCRCが作成される 。 OpenShiftのWebコンソールへアクセスする際には、ベアメタルマシンへリモデスした上でマシン上のブラウザからアクセスする必要がある。 環境確認  [root@localhost ~]# cat /etc/redhat-release CentOS Linux release 7.7.1908 (Core) 手順 公式ドキュメントの手順に沿ってインストールする。\n1.NetworkManagerをインストールする [root@localhost ~]# yum -y install NetworkManager 2.資材をダウンロードして、解凍して、パスの通ったフォルダへ移動 [root@localhost ~]# yum -y install wget [root@localhost ~]# curl -k -sS https://mirror.openshift.com/pub/openshift-v4/clients/crc/latest/crc-linux-amd64.tar.xz -o /tmp/crc-linux-amd64.tar.xz [root@localhost tmp]# cd /tmp [root@localhost tmp]# xz -dc /tmp/crc-linux-amd64.tar.xz | tar xfv - [root@localhost tmp]# cp -pi crc-linux-1.24.0-amd64/crc /usr/local/bin 3.初期セットアップ＆起動 crc startすると途中でsecretを聞かれるので、Red Hat Developer アカウントを作成して取得したsecretを入力する。完了するまで数分かかる。非rootユーザで実行する必要がある。 https://cloud.redhat.com/openshift/install/metal/user-provisioned\n[root@localhost tmp]# su - village [village@localhost tmp]$ crc setup [village@localhost ~]$ crc start 下記のような出力が表示される\nStarted the OpenShift cluster. The server is accessible via web console at: https://console-openshift-console.apps-crc.testing Log in as administrator: Username: kubeadmin Password: XtGFB-9dWLe-6B4sh-9ypMk Log in as user: Username: developer Password: developer Use the \u0026#39;oc\u0026#39; command line interface: $ eval $(crc oc-env) $ oc login -u developer https://api.crc.testing:6443 4.ocコマンドにパスを通す [village@localhost ~]$ crc oc-env [village@localhost ~]$ eval $(crc oc-env) 5.ログイン oc startしたときの出力結果に従ってoc loginする\n[village@localhost ~]$ oc login -u developer -p developer https://api.crc.testing:6443 6.動作確認 [village@localhost ~]$ oc get node NAME STATUS ROLES AGE VERSION crc-rsppg-master-0 Ready master,worker 8d v1.20.0+5fbfd19 いくつかのPodでエラーが出ているが、問題ないようである。\n[cloudg@localhost ~]$ oc get po --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE openshift-apiserver-operator openshift-apiserver-operator-7ddd5b5974-ncsqv 1/1 Running 0 7d18h openshift-apiserver apiserver-644ffb9d54-fdhc7 2/2 Running 0 7d18h openshift-authentication-operator authentication-operator-67c88594b5-zftcn 1/1 Running 0 7d18h openshift-authentication oauth-openshift-7cf7596786-cvmv5 1/1 Running 0 12h openshift-authentication oauth-openshift-7cf7596786-rgr9l 1/1 Running 0 12h openshift-cluster-machine-approver machine-approver-65cbf595f4-6l2nd 2/2 Running 0 7d18h openshift-cluster-node-tuning-operator cluster-node-tuning-operator-5c547f8bb4-7g4wk 1/1 Running 0 7d18h openshift-cluster-node-tuning-operator tuned-xkv6j 1/1 Running 0 8d openshift-cluster-samples-operator cluster-samples-operator-7969f7fcf5-9lrgb 2/2 Running 0 7d18h openshift-cluster-version cluster-version-operator-6bfbdf868f-sf2w2 1/1 Running 0 7d18h openshift-config-operator openshift-config-operator-57c76c77f7-45bt8 1/1 Running 0 7d18h openshift-console-operator console-operator-cb46c9d78-9f4qr 1/1 Running 0 7d18h openshift-console console-7985f9d77f-8vwpd 1/1 Running 0 8d openshift-console console-7985f9d77f-b7ds6 1/1 Running 0 8d openshift-console downloads-6df577f985-hdv4r 1/1 Running 0 7d18h openshift-controller-manager-operator openshift-controller-manager-operator-74ffd84cd9-qnf4b 1/1 Running 0 7d18h openshift-controller-manager controller-manager-z564h 1/1 Running 0 7d18h openshift-dns-operator dns-operator-6697cb89f5-z8vkx 2/2 Running 0 7d18h openshift-dns dns-default-bcvs5 3/3 Running 0 8d openshift-etcd-operator etcd-operator-664d45d68d-qb46f 1/1 Running 0 7d18h openshift-etcd etcd-crc-rsppg-master-0 3/3 Running 0 8d openshift-etcd etcd-quorum-guard-5df9d7748f-4j94p 1/1 Running 0 8d openshift-etcd revision-pruner-2-crc-rsppg-master-0 0/1 Completed 0 7d18h openshift-image-registry cluster-image-registry-operator-54778dff55-4mrlq 1/1 Running 0 7d18h openshift-image-registry image-registry-fdb76844c-hlgdz 1/1 Running 0 12h openshift-image-registry node-ca-6csl8 1/1 Running 0 8d openshift-ingress-canary ingress-canary-vtq2l 1/1 Running 0 8d openshift-ingress-operator ingress-operator-b877b674f-zhtnr 2/2 Running 0 7d18h openshift-ingress router-default-7d9fcbcfcb-w4sp5 1/1 Running 0 7d18h openshift-kube-apiserver-operator kube-apiserver-operator-64ff9b6958-mq8nd 1/1 Running 0 7d18h openshift-kube-apiserver kube-apiserver-crc-rsppg-master-0 5/5 Running 2 7d18h openshift-kube-apiserver revision-pruner-9-crc-rsppg-master-0 0/1 Completed 0 7d18h openshift-kube-controller-manager-operator kube-controller-manager-operator-577f6d5765-x8xpz 1/1 Running 0 7d18h openshift-kube-controller-manager kube-controller-manager-crc-rsppg-master-0 4/4 Running 0 8d openshift-kube-controller-manager revision-pruner-7-crc-rsppg-master-0 0/1 Completed 0 7d18h openshift-kube-scheduler-operator openshift-kube-scheduler-operator-67bcdc8d7f-dbxt2 1/1 Running 0 7d18h openshift-kube-scheduler openshift-kube-scheduler-crc-rsppg-master-0 3/3 Running 0 8d openshift-kube-scheduler revision-pruner-7-crc-rsppg-master-0 0/1 Completed 0 7d18h openshift-marketplace certified-operators-cmz6p 0/1 ImagePullBackOff 0 8d openshift-marketplace certified-operators-l288f 0/1 ImagePullBackOff 0 12h openshift-marketplace community-operators-4rzx2 0/1 ImagePullBackOff 0 8d openshift-marketplace community-operators-lw4r2 0/1 ImagePullBackOff 0 12h openshift-marketplace marketplace-operator-5f58b46865-zhhm9 1/1 Running 0 7d18h openshift-marketplace redhat-marketplace-dp4xm 0/1 ImagePullBackOff 0 12h openshift-marketplace redhat-marketplace-lgx2r 0/1 ImagePullBackOff 0 8d openshift-marketplace redhat-operators-tn9gl 0/1 ImagePullBackOff 0 12h openshift-marketplace redhat-operators-zcnzq 0/1 ImagePullBackOff 0 8d openshift-multus multus-admission-controller-bt42f 2/2 Running 0 8d openshift-multus multus-zt6dk 1/1 Running 0 8d openshift-multus network-metrics-daemon-jqhtz 2/2 Running 0 8d openshift-network-diagnostics network-check-source-7c9c5f694-wdg5x 1/1 Running 0 8d openshift-network-diagnostics network-check-target-7nvd2 1/1 Running 0 8d openshift-network-operator network-operator-cc56775cc-48j58 1/1 Running 0 7d18h openshift-oauth-apiserver apiserver-5f696fbd78-hxw6f 1/1 Running 0 8d openshift-operator-lifecycle-manager catalog-operator-599cd4d664-j9p69 1/1 Running 0 7d18h openshift-operator-lifecycle-manager olm-operator-fdc678f49-9nmnc 1/1 Running 0 7d18h openshift-operator-lifecycle-manager packageserver-54f669b87-kx6zm 1/1 Running 0 8d openshift-sdn ovs-f8djg 1/1 Running 0 8d openshift-sdn sdn-controller-pdqz8 1/1 Running 0 8d openshift-sdn sdn-dmgkt 2/2 Running 0 8d openshift-service-ca-operator service-ca-operator-78b9dcfcb7-28rvb 1/1 Running 0 7d18h openshift-service-ca service-ca-56bbf778b6-vtv8h 1/1 Running 0 8d 7.試験用プロジェクトの作成と、busybox podの作成 Tempプロジェクトを作成してbusybox podを作成してみる。\n[village@localhost ~]$ oc new-project temp Now using project \u0026#34;temp\u0026#34; on server \u0026#34;https://api.crc.testing:6443\u0026#34;. You can add applications to this project with the \u0026#39;new-app\u0026#39; command. For example, try: oc new-app rails-postgresql-example to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application: kubectl create deployment hello-node --image=k8s.gcr.io/serve_hostname [village@localhost ~]$ oc run busybox --restart=Never --image=busybox pod/busybox created [village@localhost ~]$ oc get po NAME READY STATUS RESTARTS AGE busybox 0/1 Completed 0 35s ","permalink":"https://kurikube.github.io/post/20210401/","summary":"概要 OpenShift4.x以降はMinishiftがなくなり、OpenShift CodeReady Container（CRC）となっている。 以下では公式ドキュメントに沿って手元のベアメタルサーバへインストールを行う。このサーバで色々なことを試してみる。 https://code-ready.github.io/crc/\n環境  ホストOS：CentOS7.7 構成図 マシン上でCRCをインストールすると自動的にNWが作成されてCRCが作成される 。 OpenShiftのWebコンソールへアクセスする際には、ベアメタルマシンへリモデスした上でマシン上のブラウザからアクセスする必要がある。 環境確認  [root@localhost ~]# cat /etc/redhat-release CentOS Linux release 7.7.1908 (Core) 手順 公式ドキュメントの手順に沿ってインストールする。\n1.NetworkManagerをインストールする [root@localhost ~]# yum -y install NetworkManager 2.資材をダウンロードして、解凍して、パスの通ったフォルダへ移動 [root@localhost ~]# yum -y install wget [root@localhost ~]# curl -k -sS https://mirror.openshift.com/pub/openshift-v4/clients/crc/latest/crc-linux-amd64.tar.xz -o /tmp/crc-linux-amd64.tar.xz [root@localhost tmp]# cd /tmp [root@localhost tmp]# xz -dc /tmp/crc-linux-amd64.tar.xz | tar xfv - [root@localhost tmp]# cp -pi crc-linux-1.24.0-amd64/crc /usr/local/bin 3.初期セットアップ＆起動 crc startすると途中でsecretを聞かれるので、Red Hat Developer アカウントを作成して取得したsecretを入力する。完了するまで数分かかる。非rootユーザで実行する必要がある。 https://cloud.","title":"OpenShift CodeReady ContainerをCentOSにインストールする（2021年時点）"},{"content":"私がGitLab CI/CD(GitLab Runner)を学んだ方法 1. Qiitaの参考記事を読んでみる GitLab CI/CDパイプライン設定リファレンス の記事を一通り読んでみる →内容がボリュームありすぎて、理解できず。。\n2.GitLabの参考書籍から読んでみる Gitlab実践ガイド(インプレス)\n GitLab実践ガイド impress top gearシリーズ    これは非常にわかりやすかったです。\n","permalink":"https://kurikube.github.io/post/20210124/","summary":"私がGitLab CI/CD(GitLab Runner)を学んだ方法 1. Qiitaの参考記事を読んでみる GitLab CI/CDパイプライン設定リファレンス の記事を一通り読んでみる →内容がボリュームありすぎて、理解できず。。\n2.GitLabの参考書籍から読んでみる Gitlab実践ガイド(インプレス)\n GitLab実践ガイド impress top gearシリーズ    これは非常にわかりやすかったです。","title":"GitLab CI/CDを学ぶのにおすすめの書籍"},{"content":"背景  Apple M1チップ搭載のMacbookだとVirtual Boxなどの一部アプリケーションが動きません。 aws コマンドを正常にインストールできるか検証してみました。  手順  pkgファイルのダウンロード  % curl \u0026#34;https://awscli.amazonaws.com/AWSCLIV2.pkg\u0026#34; -o \u0026#34;AWSCLIV2.pkg\u0026#34; % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 25.3M 100 25.3M 0 0 10.7M 0 0:00:02 0:00:02 --:--:-- 10.7M pkgのインストール  % sudo installer -pkg AWSCLIV2.pkg -target / Password: installer: Package name is AWS Command Line Interface installer: Installing at base path / installer: The install was successful. 正常にインストールできたか確認する  % aws --version aws-cli/2.2.29 Python/3.8.8 Darwin/20.3.0 exe/x86_64 prompt/off 結論  Apple M1 チップ搭載のMacbookでもawsコマンドをインストールすることが可能でした  参考サイト  https://docs.aws.amazon.com/ja_jp/cli/latest/userguide/install-cliv2-mac.html#cliv2-mac-install-cmd  ","permalink":"https://kurikube.github.io/post/20220129/","summary":"背景  Apple M1チップ搭載のMacbookだとVirtual Boxなどの一部アプリケーションが動きません。 aws コマンドを正常にインストールできるか検証してみました。  手順  pkgファイルのダウンロード  % curl \u0026#34;https://awscli.amazonaws.com/AWSCLIV2.pkg\u0026#34; -o \u0026#34;AWSCLIV2.pkg\u0026#34; % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 25.3M 100 25.3M 0 0 10.7M 0 0:00:02 0:00:02 --:--:-- 10.7M pkgのインストール  % sudo installer -pkg AWSCLIV2.pkg -target / Password: installer: Package name is AWS Command Line Interface installer: Installing at base path / installer: The install was successful.","title":"Apple M1搭載のMacBook Airにawsコマンドをインストールする"},{"content":"Hugo でyoutubeを埋め込むめのShortcode https://gohugo.io/content-management/shortcodes/#youtube にも記載のあるように、ショートコードを利用してyoutubeの動画をMarkdownに埋め込むことができます。\n例えば、https://www.youtube.com/watch?v=UUR5UFUBp5s の動画を埋め込みたい時は、Markdownの記事の中でビルトインされているショートコードを呼び出します。\n{{\u0026lt; youtube UUR5UFUBp5s \u0026gt;}} ブラウザでは以下のように出力されます。\n  参考記事  https://hugo-de-blog.com/hugo-youtube/ https://maku77.github.io/hugo/shortcode/escape.html https://blog.chick-p.work/hugo-site-directory/  ","permalink":"https://kurikube.github.io/post/20200125/","summary":"Hugo でyoutubeを埋め込むめのShortcode https://gohugo.io/content-management/shortcodes/#youtube にも記載のあるように、ショートコードを利用してyoutubeの動画をMarkdownに埋め込むことができます。\n例えば、https://www.youtube.com/watch?v=UUR5UFUBp5s の動画を埋め込みたい時は、Markdownの記事の中でビルトインされているショートコードを呼び出します。\n{{\u0026lt; youtube UUR5UFUBp5s \u0026gt;}} ブラウザでは以下のように出力されます。\n  参考記事  https://hugo-de-blog.com/hugo-youtube/ https://maku77.github.io/hugo/shortcode/escape.html https://blog.chick-p.work/hugo-site-directory/  ","title":"Hugoで作ったwebサイトにyoutubeの動画を埋め込む"},{"content":"CentOSにDockerをインストールするためのシェルスクリプトになります。 root権限で実行が楽ですが、セキュリティ的によく無いです。\nyum -y update yum -y upgrade yum install -y yum-utils device-mapper-persistent-data lvm2 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo yum install -y docker-ce docker-ce-cli containerd.io systemctl start docker systemctl enable docker ","permalink":"https://kurikube.github.io/post/20200124/","summary":"CentOSにDockerをインストールするためのシェルスクリプトになります。 root権限で実行が楽ですが、セキュリティ的によく無いです。\nyum -y update yum -y upgrade yum install -y yum-utils device-mapper-persistent-data lvm2 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo yum install -y docker-ce docker-ce-cli containerd.io systemctl start docker systemctl enable docker ","title":"Docker install用のshell-script"}]